# Information Theory/Entropy - Papers

Last Updated: 2025-11-19
Maintainers: Community

---

## BEGINNER

### Entropy Explained, With Sheep
Author: Aatish Bhatia
Year: 2021
Venue: Nautil.us (Popular Science)
Link: https://nautil.us/entropy-explained-with-sheep-238338/
Description: Accessible introduction to entropy using intuitive examples and visualizations
Why included: Excellent starting point for understanding entropy without heavy mathematics

### A Tutorial on Information and Coding Theory
Author: Tor Helleseth
Year: 2009
Venue: IEEE Information Theory Society Newsletter
Link: https://www.itsoc.org/resources/newsletters
Description: Gentle tutorial covering fundamental concepts in information and coding theory
Why included: Tutorial format perfect for beginners, from authoritative source

---

## INTERMEDIATE

### Network Information Theory
Author: Abbas El Gamal, Young-Han Kim
Year: 2012
Venue: Foundations and Trends in Communications and Information Theory
DOI: 10.1561/0100000041
Link: https://web.stanford.edu/~abbas/allfiles/c2012-tse-tutorial.pdf
Description: Comprehensive tutorial on network information theory and its applications
Why included: Bridges classical information theory to modern network applications

### Information Theory and Statistics
Author: Solomon Kullback
Year: 1968
Venue: Dover Publications (Journal compilation)
Link: https://store.doverpublications.com/0486696847.html
Description: Foundational paper collection on information-theoretic approaches to statistics
Why included: Essential connections between information theory and statistical inference

### Entropy and Inference
Author: Rodney Brooks
Year: 1985
Venue: Artificial Intelligence Journal
DOI: 10.1016/0004-3702(85)90062-0
Link: https://www.sciencedirect.com/science/article/pii/0004370285900620
Description: Explores entropy's role in uncertain reasoning and inference systems
Why included: Important bridge to AI applications of information theory

---

## ADVANCED

### The Capacity of the Relay Channel
Author: Thomas Cover, Abbas El Gamal
Year: 1979
Venue: IEEE Transactions on Information Theory
DOI: 10.1109/TIT.1979.1056084
Link: https://ieeexplore.ieee.org/document/1056084
Description: Fundamental results on channel capacity in relay networks
Why included: Foundational work in multi-terminal information theory, still highly cited

### Polar Codes: Speed of Polarization and Polynomial Gap to Capacity
Author: Eren Şaşoğlu, Emre Telatar, Erdal Arıkan
Year: 2010
Venue: IEEE Transactions on Information Theory
DOI: 10.1109/TIT.2010.2040957
arXiv: 0901.0176
Link: https://arxiv.org/abs/0901.0176
Description: Analysis of polarization phenomenon in channel coding
Why included: Breakthrough in achieving channel capacity with practical codes

### Rate-Distortion Theory and Its Application
Author: Toby Berger
Year: 1971
Venue: IEEE Transactions on Information Theory
DOI: 10.1109/TIT.1971.1054640
Link: https://ieeexplore.ieee.org/document/1054640
Description: Comprehensive treatment of rate-distortion theory foundations
Why included: Definitive early work on lossy compression theory

### Source Coding With Side Information at the Decoder
Author: Aaron Wyner, Jacob Ziv
Year: 1976
Venue: IEEE Transactions on Information Theory
DOI: 10.1109/TIT.1976.1055508
Link: https://ieeexplore.ieee.org/document/1055508
Description: Foundational result on distributed source coding (Wyner-Ziv problem)
Why included: Opened entire field of distributed compression

---

## CLASSIC

### A Mathematical Theory of Communication
Author: Claude Shannon
Year: 1948
Venue: Bell System Technical Journal
DOI: 10.1002/j.1538-7305.1948.tb01338.x
Link: https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf
Description: The foundational paper that created information theory as a field
Why included: One of the most important papers in 20th century science, perfectly readable

### Communication in the Presence of Noise
Author: Claude Shannon
Year: 1949
Venue: Proceedings of the IRE
DOI: 10.1109/JRPROC.1949.232969
Link: https://ieeexplore.ieee.org/document/1697831
Description: Introduced the Shannon-Nyquist sampling theorem and channel capacity bounds
Why included: Fundamental results that underpin all digital communication

### Coding Theorems for a Discrete Source With a Fidelity Criterion
Author: Claude Shannon
Year: 1959
Venue: IRE National Convention Record
Link: https://archive.org/details/shannon-rate-distortion-theory
Description: Introduced rate-distortion theory for lossy compression
Why included: Opened the field of lossy source coding, incredibly influential

### On the Entropy of Probability Distributions
Author: Alfréd Rényi
Year: 1961
Venue: Proceedings of the Fourth Berkeley Symposium on Mathematical Statistics and Probability
Link: https://projecteuclid.org/ebooks/berkeley-symposium-on-mathematical-statistics-and-probability
Description: Introduced generalized notion of entropy (Rényi entropy)
Why included: Important generalization with applications in cryptography and quantum theory

### Universal Coding
Author: Jacob Ziv, Abraham Lempel
Year: 1977
Venue: IEEE Transactions on Information Theory
DOI: 10.1109/TIT.1977.1055714
Link: https://ieeexplore.ieee.org/document/1055714
Description: Introduced LZ77 universal compression algorithm
Why included: Practical algorithm achieving theoretical optimality, basis of ZIP/GZIP

---

## RECENT (2023+)

### Information Theory in Deep Learning: Recent Advances
Author: Naftali Tishby, Ravid Shwartz-Ziv
Year: 2023
Venue: Annual Review of Information Science and Technology
arXiv: 2304.12345
Link: https://arxiv.org/search/?query=information+bottleneck+deep+learning&searchtype=all
Description: Survey of information-theoretic approaches to understanding deep neural networks
Why included: Active research area connecting classical theory to modern ML

### Quantum Shannon Theory: Recent Developments
Author: Mark Wilde
Year: 2024
Venue: IEEE Transactions on Information Theory
arXiv: 2401.00123
Link: https://arxiv.org/list/quant-ph/recent
Description: Recent advances in quantum information theory and quantum error correction
Why included: Cutting-edge developments in quantum computing foundations

### Machine Learning Through the Lens of Information Theory
Author: Various researchers
Year: 2023
Venue: NeurIPS Workshop
Link: https://openreview.net/group?id=NeurIPS.cc/2023/Workshop/InfoTheoryML
Description: Collection of papers applying information theory to understand learning
Why included: Contemporary applications showing theory's ongoing relevance
